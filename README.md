<h1 align="center">ğŸ“ IBM Machine Learning with Python â€“ Complete Course Repository</h1>

<p align="center">
  <a href="https://www.python.org/"><img src="https://img.shields.io/badge/Made%20with-Python-blue?logo=python"></a>
  <a href="https://scikit-learn.org/"><img src="https://img.shields.io/badge/Framework-Scikit--learn-orange?logo=scikitlearn"></a>
  <a href="https://www.coursera.org/learn/machine-learning-with-python"><img src="https://img.shields.io/badge/Course-IBM%20Machine%20Learning%20with%20Python-lightblue?logo=ibm"></a>
  <img src="https://img.shields.io/badge/Status-Completed-success">
</p>

> ğŸ§  A comprehensive collection of my notes, hands-on projects, and key learnings from the **IBM Machine Learning with Python (Coursera)** course â€” demonstrating mastery in data preprocessing, supervised and unsupervised learning, model evaluation, and pipeline automation.

---

## ğŸ“˜ Course Overview

The **Machine Learning with Python** course by **IBM Skills Network** introduces learners to the foundational principles of machine learning, data handling, and predictive modeling using Python and Scikit-learn.  
This repository documents my complete learning journey through all **six modules**, including detailed notes, practical labs, and real-world projects.

---

## ğŸ¯ Course Learning Outcomes

- Understand the **concepts and types** of machine learning: supervised, unsupervised, and reinforcement  
- Build **regression and classification** models using Scikit-learn  
- Explore **decision trees**, **SVM**, **KNN**, and **ensemble methods** like Random Forest & XGBoost  
- Apply **clustering** and **dimensionality reduction** (K-Means, DBSCAN, PCA)  
- Master **model evaluation**, **cross-validation**, and **regularization** techniques  
- Design **ML pipelines** to automate preprocessing and hyperparameter tuning  
- Complete **end-to-end machine learning projects** on real-world datasets  

---

## ğŸ§© Modules & Projects Summary

| # | Module | Focus Area | Projects |
|---|---------|-------------|-----------|
| **1** | **Introduction to Machine Learning** | Overview of ML, types of learning, ML lifecycle, and Scikit-learn ecosystem | â€“ Notes Only |
| **2** | **Regression Analysis** | Linear, Multiple, Polynomial, and Logistic Regression | `Regression_Trees_Taxi_Tip.ipynb` |
| **3** | **Classification & Decision Trees** | KNN, Decision Trees, Random Forest, XGBoost, SVM | `decision_tree_svm_ccFraud.ipynb` Â· `Random_Forests_XGBoost.ipynb` |
| **4** | **Unsupervised Learning** | K-Means, DBSCAN, HDBSCAN, PCA, t-SNE, UMAP | `K-Means-Customer-Seg.ipynb` Â· `Comparing_DBScan_HDBScan.ipynb` Â· `PCA.ipynb` |
| **5** | **Model Evaluation & Regularization** | Cross-validation, Pipelines, GridSearchCV, Ridge & Lasso Regularization | `Evaluating_random_forest.ipynb` Â· `Regularization_in_LinearRegression.ipynb` |
| **6** | **Final Project & Course Summary** | End-to-end supervised learning pipeline, evaluation & model comparison | `Titanic_Survival_Prediction.ipynb` Â· `FinalProject_AUSWeather.ipynb` |

---

## ğŸ“š Notes Included

Each module includes **summarized PDF notes** containing key formulas, code snippets, and conceptual explanations for quick reference.

| File | Description |
|------|--------------|
| `Machine_Learning_Notes_M1.pdf` | Machine Learning Fundamentals |
| `Machine_Learning_Notes_M2.pdf` | Regression Models |
| `Machine_Learning_Notes_M3.pdf` | Classification, Decision Trees & Ensemble Models |
| `Machine_Learning_Notes_M4.pdf` | Unsupervised Learning & Dimensionality Reduction |
| `Machine_Learning_Notes_M5.pdf` | Model Evaluation, Validation & Regularization |
| `Machine_Learning_Notes_M6.pdf` | Final Project Summary & Course Wrap-up |

---

## âš™ï¸ Tools & Libraries

- **Language:** Python ğŸ  
- **Libraries:**  
  `pandas` Â· `numpy` Â· `matplotlib` Â· `seaborn` Â· `scikit-learn` Â· `xgboost` Â· `hdbscan` Â· `plotly`  
- **Core Techniques:**  
  - Data Cleaning & Feature Engineering  
  - Regression & Classification Models  
  - Clustering & PCA  
  - Regularization (Ridge, Lasso)  
  - Cross-validation & Grid Search  
  - Pipelines & Model Optimization  
  - Model Evaluation Metrics (MAE, MSE, RMSE, RÂ², Precision, Recall, F1-score)  

---

## ğŸ“Š Key Learnings & Insights

### ğŸ”¹ Machine Learning Concepts
- ML is a subset of AI enabling systems to **learn from data** and **make decisions** without explicit programming.  
- Includes **supervised learning** (labeled data), **unsupervised learning** (unlabeled data), and **reinforcement learning** (reward-based).

### ğŸ”¹ Data Processing & Feature Engineering
- Importance of handling missing values, scaling, encoding, and feature selection.  
- Use of `ColumnTransformer` and `Pipeline` for clean, repeatable workflows.

### ğŸ”¹ Model Evaluation
- Avoid overfitting via **cross-validation** and **regularization**.  
- Evaluate performance using metrics tailored to the problem type.  
- Understand trade-offs: **bias vs variance**, **accuracy vs interpretability**.

### ğŸ”¹ Project Insights
- **Regression** â†’ Predict continuous variables like taxi tips or housing prices.  
- **Classification** â†’ Identify patterns in data such as survival prediction or rainfall detection.  
- **Clustering & PCA** â†’ Discover natural patterns and simplify high-dimensional data.  
- **End-to-End Pipelines** â†’ Combine preprocessing, modeling, and evaluation for reproducible results.

---

## ğŸŒ¦ï¸ Highlight Projects

### ğŸ§­ Final Project â€“ **Rainfall Prediction (Australia Weather)**
- Built an end-to-end rainfall classifier using **Random Forest** and **Logistic Regression**  
- Achieved ~84% accuracy with **GridSearchCV** and **Stratified Cross-Validation**  
- Key features: `Humidity3pm`, `RainYesterday`, `WindGustSpeed`  
- Included **feature importance visualization** and model comparison  

### ğŸš¢ Practice Project â€“ **Titanic Survival Prediction**
- Predicted survival likelihood using demographic and travel data  
- Implemented preprocessing pipelines, one-hot encoding, and hyperparameter tuning  
- Compared **Random Forest** and **Logistic Regression**, both achieving ~83% accuracy  

---

## ğŸ§© Skills Demonstrated

âœ… Data preprocessing & cleaning  
âœ… Model training, validation, and comparison  
âœ… Cross-validation and hyperparameter tuning  
âœ… Feature selection & engineering  
âœ… Building ML pipelines  
âœ… Visualization of model results  
âœ… Documentation and reproducibility  

---

## ğŸ Certificate

ğŸ“ **IBM Machine Learning with Python (Coursera)**  
Completed successfully as part of the **IBM Data Science Professional Certificate**.

[ğŸ”— View Course](https://www.coursera.org/learn/machine-learning-with-python)

---

## ğŸ‘¨â€ğŸ’» Author

**Sandeep Maurya**

ğŸ“§ [isandeeep06@gmail.com](mailto:isandeeep06@gmail.com)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/sandeepmaurya-datascientist)

 ğŸ§©*Aspiring Data Scientist & ML Engineer*
---

## ğŸŒŸ Support

If this repository helped you:  
â­ **Star this repo** â€” it motivates me to share more learning projects!  
ğŸ“¢ **Share it** with your peers and aspiring data scientists  
ğŸ’¬ **Feedback or suggestions?** Open an issue or connect on LinkedIn  

---

> _â€œMachine Learning isnâ€™t just about algorithms â€” itâ€™s about understanding data, designing pipelines, and building systems that learn from the world.â€_ ğŸ¤–
